\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{float}
\usepackage[table,xcdraw]{xcolor} %para usar tablas con color de fondo en las celdas
\usepackage{hyperref} %para poder poner enlaces
\usepackage{listings} %para insertar código
\usepackage{tikz}%para pintar las redes neuronales
\usepackage{color} %para poder definir y usar colores
\usepackage{soul} %para hacer los subrayados

\author{\textbf{Gustavo Rivas Gervilla}}
\title{\textcolor{deepblue}{\textbf{Redes Neuronales para MNIST}}}
\date{}

%Configurando lstlisting para mostrar código Python con algún 	 de colores (copiado de http://tex.stackexchange.com/questions/83882/how-to-highlight-python-syntax-in-latex-listings-lstinputlistings-command) ------------------------------
% Custom colors
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{light-gray}{gray}{0.85}
\definecolor{comment-gray}{gray}{0.65}
\definecolor{light-green}{rgb}{0.66,1,0.5}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{8} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{8}  % for normal

%Configuración de los listings
\lstset{
	language=Python,
	basicstyle=\ttm,
	otherkeywords={self},             % Add keywords here
	keywordstyle=\ttb\color{deepblue},
	emph={MyClass,__init__},          % Custom highlighting
	emphstyle=\ttb\color{deepred},    % Custom highlighting style
	stringstyle=\color{deepgreen},
	frame=tb,                         % Any extra options here
	showstringspaces=false,            % 
	commentstyle=\ttm\color{comment-gray}, % Custom comment style
}
%--------------------------------------------------------------------------------

\newcommand{\code}[1]{\sethlcolor{light-gray}\hl{\texttt{#1}}} %Comando para poner código inline
\newcommand{\archive}[1]{\sethlcolor{light-green}\hl{\texttt{#1}}} %Comando para resaltar nombres de archivos
\renewcommand\tablename{Tabla} %Cambiar el nombre de las tablas
\renewcommand\figurename{Figura} %Cambiar el nombre de las tablas
\renewcommand{\contentsname}{Índice} %Cambiar el nombre de la ToC

\begin{document}
\maketitle
\begin{center}
\textbf{IC. Máster Universitario en Ingeniería Informática}
\newline
\newline
\newline
\includegraphics[scale=0.5]{img/decsai}
\end{center}

\newpage
\tableofcontents
\newpage

%Definición de variables para tikz
\def\layersep{2.5cm}

\section{Introducción}

En esta práctica se pretende probar distintos algoritmos de aprendizaje y topologías para redes neuronales a fin de identificar dígitos manuscritos en las imágenes de la base de datos MNIST. Se cuenta con 60000 muestras de entrenamiento y otras 10000 para testear la bondad de los algoritmos probados, que sería medida en términos de la tasa de error.\\

Las imágenes se cargarán de sendos ficheros comprimidos empleando el código que podemos encontrar en el fichero \archive{reader.py} el cuál se encarga de obtener cada imagen del fichero comprimido, formateando correctamente los bytes que se van leyendo de dicho fichero y normalizando las imágenes para su posterior almacenamiento (en el directorio \archive{data}) y uso. Para realizar esta descompresión y normalización nos hemos basado en el código Java facilitado por el profesor a tal efecto.

\section{Herramientas y entorno de desarrollo}
Para la realización de esta práctica hemos optado por emplear el lenguaje \textbf{Python 3} pese a que podemos pensar que no es tan eficiente como otros lenguajes, tiene la ventaja de contar con el módulo \textbf{Numpy} cuyas operaciones están programadas en código C lo que lo hace muy eficiente para realizar cálculos matriciales.\\

No obstante nosotros vamos a trabajar con otro módulo Python llamado \href{http://deeplearning.net/software/theano/index.html}{Theano} el cuál nos permite, de un modo transparente, realizar cálculos en la GPU, lo que en la mayoría de los casos hará que los cálculos a realizar sean mucho más eficientes. Aunque hemos de tener cuidado ya que, en primer lugar los cálculos han de realizarse empleando float32 en lugar de float64 para que se puedan realizar efectivamente en la GPU (en caso de no poderse realizar en GPU automáticamente se lanzarán en CPU a no ser que empleemos el flag \textit{force\_devide=True}). Por otro lado habrá código que se ejecuten más lento en la GPU que en la CPU ya sea porque no los hemos programado bien o porque no suponen un volumen de trabajo suficiente como para que la sobrecarga de enviar la información a la GPU sea rentable. No obstante pese a que no podamos realizar las operaciones en la GPU, las operaciones y funciones que proporciona \code{Theano} están también optimizadas, además de que la funciones Theano que declaremos serán compiladas, lo que las hace más rápidas.\\

A fin de poder emplear esta computación en GPU ejecutaremos el archivo \archive{reader.py} la instrucción \code{THEANO\_FLAGS=mode=FAST\_RUN,device=cpu,floatX=float32 python reader.py}.\\

En la \href{http://deeplearning.net/software/theano/tutorial/using_gpu.html}{página} de Theano donde se nos explica cómo usar la GPU, hay un código de ejemplo el cuál se ejecuta en menos de 1/3 del tiempo que se consumiría ejecutando dicho código en CPU.

Por otro lado podemos encontrar un ejemplo sobre cómo programar una red neuronal que trabaje con minilotes de un modo eficiente usando la funcionalidad de Theano:

\begin{lstlisting}
import numpy as np

import theano
import theano.tensor as tensor

x = np.load('data_x.npy')
y = np.load('data_y.npy')

# symbol declarations
sx = tensor.matrix()
sy = tensor.matrix()
w = theano.shared(np.random.normal(avg=0, std=.1,
                                   size=(784, 500)))
b = theano.shared(np.zeros(500))
v = theano.shared(np.zeros((500, 10)))
c = theano.shared(np.zeros(10))

# symbolic expression-building
hid = tensor.tanh(tensor.dot(sx, w) + b)
out = tensor.tanh(tensor.dot(hid, v) + c)
err = 0.5 * tensor.sum(out - sy) ** 2
gw, gb, gv, gc = tensor.grad(err, [w, b, v, c])

# compile a fast training function
train = theano.function([sx, sy], err,
    updates={
        w: w - lr * gw,
        b: b - lr * gb,
        v: v - lr * gv,
        c: c - lr * gc})

# now do the computations
batchsize = 100
for i in xrange(1000):
    x_i = x[i * batchsize: (i + 1) * batchsize]
    y_i = y[i * batchsize: (i + 1) * batchsize]
    err_i = train(x_i, y_i)
\end{lstlisting}

Este código nos servirá de guía para implementar los distintos algoritmos sobre redes neuronales que probaremos en esta práctica. Destacaría dos cosas del código anterior: cómo se definen las funciones para ser compiladas a fin de trabajar en GPU y lo sencillo que resulta calcular el gradiente del error para realizar la propagación hacia atrás, por supuesto contamos con que dicha operación esté optimizada.\\

Las pruebas se realizarán en un ordeandor con \textbf{Arch Linux 64b}, \textbf{8 GB} de memoria RAM, un procesador \textbf{Intel Core i7-6700HQ} a 3.5 GHz y una tarjeta gráfica \textbf{NVIDIA GeForce GTX 950M}.

\section{Algoritmos basados en plantillas}

A continuación vamos a ver los primeros algoritmo de aprendizaje que vimos en clase y que son de un funcionamiento muy básico. Estos algoritmos podríamos decir que están basados en plantillas ya que tenemos una neurona por cada uno de los dígitos a distinguir y se irán actualizando los peso de cada una a fin de reforzar aquellos píxeles que forman parte del número que cada una ha de reconocer y se irán debilitando los pesos de los píxeles que no forman parte del dígito que tienen que reconocer, y que por tanto sólo puede llevar a la neurona, y por última instancia a la red, a confusión. Por esto decimos que estos algoritmos se basan en plantillas, cada neurona almacenará una plantilla 28x28 que le dará los pesos que necesita para reconocer el dígito concreto que ha de reconocer. Contemplaremos tres aproximaciones, con una topología que podríamos describir por medio del siguiente esquema:

\begin{center}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=\layersep]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
    \tikzstyle{entry}=[circle,fill=green!50,minimum size=5pt,inner sep=0pt]
    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=10pt,inner sep=0pt]
    \tikzstyle{hidden neuron}=[neuron, fill=orange!50];
    \tikzstyle{annot} = [text width=4em, text centered]

    % Draw the input layer nodes
    \foreach \name / \y in {0,1}
    % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
        \node[entry, pin=left:$pixel_{\y}$] (I-\name) at (0,-0.5*\y cm) {};
    
    \node at (-1,-0.5*3) {\vdots};
    \node[entry, pin=left:$pixel_{782}$] (I-782) at (0,-0.5*5) {};
    \node[entry, pin=left:$pixel_{783}$] (I-783) at (0,-0.5*6) {};

    % Draw the hidden layer nodes
    \foreach \name / \y in {0,...,9}
        \path[yshift=0.5cm]
            node[hidden neuron, pin={[pin edge={->}]right:$salida_{\y}$}] (H-\name) at (\layersep,-0.5*\y cm) {};

    % Connect every node in the input layer with every node in the
    % hidden layer.
    \foreach \source in {0,1,782,783}
        \foreach \dest in {0,...,9}
            \path (I-\source) edge (H-\dest);

    % Annotate the layers
    \node[annot,above of=H-0, node distance=1cm] (hl) {Salidas};
    \node[annot,left of=hl] {Entradas};    
\end{tikzpicture}
\end{center}

\subsection{Penalización fija por equivocación (Plantillas 1)}
\archive{algTemplates1.py}\\

Este algoritmo es muy sencillo, lo que hace es aumentar o disminuir una cantidad fija (\code{lr}) a aquellos pesos de la neurona que ha ganado la votación (que sería aquella tal que el valor $\underset{j = 0}{\overset{28^2-1}{\Sigma}} w_{ij}img_j$, donde $w_{ij}$ es el peso de la neurona i-ésima para el píxel $j$ de la imagen, es el más alto) correspondientes a los píxeles activos de la imagen; aquellos con un valor superior a cero en la imagen.\\

Hay que señalar que en caso de realizar esta actualización a todos los pesos de la neurona, en lugar de sólo a los activos, entonce el error sería mucho más grande (aprox. un 85\%). Esto se debe a que estamos trabajando con algoritmos que sólo cambian su información de aprendizaje según la imagen que le damos como entrada, entonces si aportamos información a través de pesos correspondientes a píxeles de la imagen que no contenían información, lo único que hacemos es ``confundir'' a la red.

\subsection{Penalización fija y refuerzo de neurona correcta (Plantillas 2)}
\archive{algTemplates2.py}\\

En este caso y en el anterior es mucho menor el tiempo al ejecutar el cógido en CPU que en GPU (en CPU tadamos menos de 3 segundos y en cambio en GPU tarda algo más de 25), es decir, tal y como está planteado el algoritmo la sobrecarga que supone trasladar la información a la GPU es mayor que el tiempo de ejecución del algoritmo en sí.\\

Hay algo que destacar y es que en una primera prueba se había omitido el vector de bias, y el error era ligeramente menor que al incorporarlo. En mi opinión esto se debe a que como estamos trabajando con un sistema de plantillas lo único que hacemos al incorporar este elemento es introducir una información que realmente es ficticia; la actualización de pesos viene sólo dada por los píxeles activos en la imagen de entrada.\\

Este algoritmo mejora sustancialmente al anterior en tasa de error puesto que no sólo se limita a penalizar o compensar a la neurona que dio la salida mayor, la que se consideraría para la clasificación, sino que además en todos los casos se refuerza aquella neurona que debería haber sido la que diese la clase correcta de la imagen. Aunque no vamos a mostrar el código entero ya que detalles importantes del mismo se aclaran para el código del siguiente algoritmo, sí que vamos a mostrar el código que actualiza los pesos de la red:

\begin{lstlisting}
for img, lbl in zip(imgs, lbls):
    predicted = np.argmax(dot(img, w))
    if (predicted == lbl):
        w[img > 0,predicted] += lr
    else:
        w[img > 0, int(lbl)] += lr
        w[img > 0, predicted] -= lr
\end{lstlisting}

Aquí podemos ver cómo se calcular la clase predicha por la red neuronal y en caso de acertar se refuerza la neurona que la predijo, seleccionando sólo aquellos pesos asociados a píxeles activos en la imagen (\code{img > 0}) y en otro caso se penaliza esa neurona y se refuerza la neurona correcta.

\subsection{Actualización de pesos según el error (Plantillas 3)}
\archive{algTemplates3.py}\\

Para este algoritmo nos hemos basado en el siguiente enlace: \url{https://mmlind.github.io/Simple_1-Layer_Neural_Network_for_MNIST_Handwriting_Recognition/}. Lo primero que necesitaremos es algo que también vamos a necesitar cuando pasemos a trabajar con algoritmos de aprendizaje más sofisticados, pasamos de tener las etiquetas representadas por un número entero por tener cada una representada por un array binario que tiene un 1 sólamente en aquella posición correspondiente a la etiqueta. Este código también lo tenemos en el archivo \archive{reader.py} y almacena estas etiquetas en el archivo \archive{data/binTrainLbl.npy}.\\

Este algoritmo pretende contruir una plantilla pero empleando más información que la que usábamos en los dos algoritmo anteriores, ahora el incremento que se le añade a cada peso de la red neuronal es distinto en función del error cometido por la neurona a la que pertenece (diferencia entre el \textit{output} de esa neurona y la que debería ser, modelada por el vector binario anteriormente generado) y la entrada que se introdujo por esa dendríta de la neurona. Con lo cual el cambio que realizamos al peso viene dado según el error cometido y según el peso que tuviese el píxel de esa imagen en la salida de la neurona. Entonces si nos fijamos estamos ante un algoritmo que sólo actualiza los pesos relativos a píxeles activos en la imagen de entrada, como hacían los dos algoritmos anteriores, pero considerando más información que emplear una tasa de aprendizaje fija.

Tanto para este algoritmo como para los dos anteriores, dado que el tiempo de entrenamiento es muy reducido hemos optado por no almacenar los pesos de la red en un archivo para futuros usos, no obstante sí que fijamos la semilla aleatoria al inicio del algoritmo de modo que la inicialización de pesos de las neuronas sea siempre la misma. Se ha probado también a cambiar dicha semilla para asegurar que los resultados obtenidos no se deben al azar de los pesos obtenidos, y se han obtenido resultados muy similares.\\

Además la ejecución de este algoritmo nos ha permitido comprobar que lo que estamos haciendo en cuanto a la codificación de imágenes y las tasas de error calculadas es correcto, ya que obtenemos una tasa de error muy parecida a la que obtiene el desarrollador que ha publicado el algoritmo en el enlace anteriormente mencionado. Vamos ahora a mostrar el código desarrollado a fin de dar algunas ideas sobre la programación con \code{Theano}, que es lo que estamos empleado para las prácticas:\\

\begin{lstlisting}
import numpy as np
import time
import theano.tensor as T
from theano import function, config, scan, shared
from constants import *

np.random.seed(12345678)

lr = 0.1 #learning rate

imgs = np.load("data/trainImg.npy")
binLbls = np.load("data/binTrainLbl.npy")
lbls = np.load("data/trainLbl.npy")
imgsTest = np.load("data/testImg.npy")
lblsTest = np.load("data/testLbl.npy")

x = T.vector('x')
y = T.vector('y')
A = T.matrix('A')

#initialize weights in [0,1]
w = shared(np.random.rand(ROWS*COLS, 10).astype(config.floatX))

out = T.dot(x, w)/(28.0*28.0)
err = y - out

#gw represents the weight increments
gw, aux = scan(lambda scalar,x: scalar * x, sequences=[err], non_sequences=x)

#function that trains the NN with a train image, update weights
train = function([x, y], err, updates = {w: w + (lr * gw.T)})

#NN training
t0 = time.time()
for img, lbl in zip(imgs, binLbls):
    train(img, lbl)
t1 = time.time()

print("Training time: ", (t1-t0))

#function that computes vector matrix product
dot = function([x,A], T.dot(x,A))

predictedTest = []
errors = 0
for img, lbl in zip(imgsTest, lblsTest):
    p = np.argmax(dot(img, w.get_value()))
    predictedTest.append(p)
    if p != lbl:
        errors += 1
print("Test errors:", errors, "Error rate:", errors*100.0/NTEST)

predictedTrain = []
errors = 0
for img, lbl in zip(imgs, lbls):
    p = np.argmax(dot(img, w.get_value()))
    predictedTrain.append(p)
    if p != lbl:
        errors += 1

print("Train errors:", errors, "Train error rate:", errors/NTRAIN*100, "%")
\end{lstlisting}

Lo primero que observamos es la fijación de la semilla aleatoria y la declaración de la tasa de aprendizaje, \code{lr}, a continuación cargamos todos los datos de la base. Ahora ya encontramos código de Theano, en primer lugar estamos definición unas variables simbólicas que nos servirán como base para definir otras tantas, con estas variables es con las que definimos las funciones Theano que serán compiladas.\\

Así denimos una variable \textit{shared}, \code{w}, que es una matriz $28^2 \mathrm{x} 10$ que representa los pesos de las diferentes neuronas que conforman la única capa de la topología que emplean estos algoritmos. La disponemos de este modo ya que después multiplicaremos un vector fila por ella y con lo cual las dimensiones tienen que ser las adecuadas.\\

A continuación definimos la variable que representará la salida, como vemos esta variable será el resultado de multiplicar el vector, que será la variable de entrada, por cada columna de la matriz, normalizado de modo que la salida quede en el [0,1]. Y definimos el error como un vector que será la diferencia entre el vector esperado, que representa la clase de la imagen de entrada, y la salida obtenida.\\

Ahora vamos a calcular la matriz de incrementos para la matriz de pesos, \code{gw}, esto lo hacemos por medio de la función \code{scan} de Theano que es algo parecido a los bucles de Theano que resultan algo más rápidos que un for usual; se realizó un pequeño experimento y se notó la diferencia de tiempos. Con esto definimos una nueva variable que almacena el resultado de multiplicar la entrada (representada por la variable simbólica \code{x}) por el error de cada una de las neuronas, representado por el vector simbólico \code{err}, que se recorre elemento a elemento y por esto se añada a la lista de \code{sequences} de la función \code{scan}; con la variable aux sólo recogemos el otro elemento devuelto por esta función que no vamos pasar a explicar pues no nos interesa en este momento.\\

Por último definimos una función Theano con el comando \code{function} que recibe como entradas dos vectores, que serán la imagen y el vector binario que codifica la clase de asociada a a imagen por medio de un vector binario, que calcula la variable \code{err} para dichas entradas y actualiza la matriz de pesos, \code{w}, sumándole la matriz de incrementos que se deriva del error, multiplicada por la tasa de aprendizaje. Dicha actualización la realizamos por medio del parámetro \code{updates} del contructor de funciones de Theano. Diciéndole qué actualizar y con qué nuevo valor.\\

Después recorremos en un bucle usual de Python las imágenes de entrenamiento junto con sus vectores binarios de etiquetas y usamos la función que acabamos de definir para ir actualizando los pesos de la matriz según la salida obtenida para estas imágenes. Luego no hacemos más que emplear la red entrenada para obtener la clase que nos da para las imágenes de test y train, que será la correspondiente a la salida más alta de las diez neuronas (por esto empleamos \code{argmax}) y calculamos el número de errores obtenido. Observemos que también hemos definido una función para calcular el producto de un vector por una matriz con tal propósito.\\

Aquí recogemos los resultados obtenidos por estos tres algoritmos. Como vemos no se han almacenado en un fichero los pesos de las correspondientes redes entrenadas ya que, como son algoritmos muy rápidos, no se ha considerado necesario:

\begin{table}[H]
\centering
\caption{Resumen de resultados plantillas}
\label{my-label}
\begin{tabular}{|
>{\columncolor[HTML]{FFFFC7}}c |c|c|c|c|c|}
\hline
\cellcolor[HTML]{FFFC9E}\textbf{Algoritmo} & \cellcolor[HTML]{9AFF99}\textbf{\begin{tabular}[c]{@{}c@{}}Archivo\\ algoritmo\end{tabular}} & \cellcolor[HTML]{9AFF99}\textbf{\begin{tabular}[c]{@{}c@{}}Archivo \\ pesos\end{tabular}} & \cellcolor[HTML]{FD6864}\textbf{\begin{tabular}[c]{@{}c@{}}\% Error\\ entrenamiento\end{tabular}} & \cellcolor[HTML]{FD6864}\textbf{\begin{tabular}[c]{@{}c@{}}\% Error\\ test\end{tabular}} & \cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}c@{}}Tiempo \\ entrenamiento\end{tabular}} \\ \hline
Plantillas 1                               & algTemplates1.py                                                                             & -                                                                                         & 44.17                                                                                                  & 44.17                                                                                         & 2.33                                                                                                  \\ \hline
Plantillas 2                               & algTemplates2.py                                                                             & -                                                                                         & 17.65                                                                                                   & 16.43                                                                                          & 2.36                                                                                                  \\ \hline
Plantillas 3                               & algTemplates3.py                                                                             & -                                                                                         & 16.13                                                                                                   & 15.52                                                                                          & 1.84                                                                                                  \\ \hline
\end{tabular}
\end{table}

\section{Backpropagation}

A continuación vamos a pasar a trabajar con redes neuronales que emplean el \newline mecanismo de propagación hacia atrás para actualizar los pesos de las neuronas que la forman, tendremos una red muy simple con una sola capa oculta. Así la topología que tendremos de inicio será la siguiente será la siguiente:

\begin{center}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!10, node distance=\layersep]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=10pt,inner sep=0pt]
    \tikzstyle{input neuron}=[neuron, fill=green!50, minimum size=5pt];
    \tikzstyle{output neuron}=[neuron, fill=orange!50, minimum size =10pt];
    \tikzstyle{hidden neuron}=[neuron, fill=gray!50];
    \tikzstyle{annot} = [text width=4em, text centered]

    % Draw the input layer nodes
    \foreach \name / \y in {0,1}
    % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
        \node[input neuron, pin=left:$pixel_{\y}$] (I-\name) at (0,-0.5*\y cm) {};
    
    \node at (0,-0.5*3) {\vdots};
    \node[input neuron, pin=left:$pixel_{782}$] (I-782) at (0,-0.5*5) {};
    \node[input neuron, pin=left:$pixel_{783}$] (I-783) at (0,-0.5*6) {};

    % Draw the hidden layer nodes
    \node at (\layersep,-0.5*3) {\vdots};
    \foreach \name / \y in {0,1,7,8}
        \path[yshift=0.5cm]
            node[hidden neuron] (H-\name) at (\layersep,-0.5*\y cm) {};
    
    %Draw output layer nodes  
    \foreach \name / \y in {0,...,9}
        \path[yshift=0.5cm]
            node[output neuron, pin={[pin edge={->}]right:$salida_{\y}$}] (O-\name) at (2*\layersep,-\y*0.5 cm) {};

    % Connect every node in the input layer with every node in the
    % hidden layer.
    \foreach \source in {0,1,782,783}
        \foreach \dest in {0,1,7,8}
            \path (I-\source) edge (H-\dest);

    % Connect every node in the hidden layer with the output layer
    \foreach \source in {0,1,7,8}
    		\foreach \dest in {0,...,9}
        		\path (H-\source) edge (O-\dest);

    % Annotate the layers
    \node[annot,above of=H-0, node distance=1cm] (hl) {Capa oculta};
    \node[annot,left of=hl] {Entradas};
    \node[annot,right of=hl] {Salidas};
\end{tikzpicture}
\end{center}

Los experimentos realizados para ajustar los parámetros de la red se han realizado atendiendo a la tasa de error en el conjunto de test. En la práctica deberían hacerse sobre un conjunto de validación, pero para poder emplear todas las muestras de entrenamiento disponibles para entrenar la red hemos optado por esta opción. También es habitual realizar \textit{deformaciones} a los datos de train a fin de poder contar con un número más elevado de muestras para el entrenamiento y poder tener así un conjunto de validación, sin embargo no se ha optado por tal alternativa.\\

Gracias a la posibilidad de realizar cálculo simbólico con la libería Theano implementar los algoritmos de este estilo resulta muy sencillo ya que no necesitamos calcular el gradiente del error respecto a los distintos pesos de la red neuronal para poder propagar el error. Simplemente tenemos que realizar una declaración de variables simbólicas como la que se muestra en el siguiente fragmento de código que extraído del archivo \archive{backSoft.py}.

\begin{lstlisting}
W1 = shared(np.random.normal(loc=0, scale=.1, size=(784, nHidden))
.astype(config.floatX), name = 'W1')
b1 = shared(np.random.normal(loc=0, scale=.1, size=nHidden)
.astype(config.floatX), name = 'b1')
W2 = shared(np.random.normal(loc=0, scale=.1, size=(nHidden, 10))
.astype(config.floatX), name = 'W2')
b2 = shared(np.random.normal(loc=0, scale=.1, size=10)
.astype(config.floatX), name = 'b2')


hid = 1.0 / (1.0 + T.exp(-(T.dot(x, W1) + b1)))
out = 1.0 / (1.0 + T.exp(-(T.dot(hid, W2) + b2)))
y_hat = T.nnet.softmax(out)
err = - T.sum(y * T.log(y_hat))
prediction = T.argmax(y_hat)

#define gradients
dW1, db1, dW2, db2 = T.grad(err, [W1, b1, W2, b2])
\end{lstlisting}

Como podemos ver declaramos diversas variables simbólicas entre las que se encuentran las matrices de pesos de la red, y definimos una variable simbólica \code{err} que representa el error de entropía cruzada, que es la función de coste asociada a una capa de salida de tipo softmax. Finalmente definimos las variables \code{dW1, db1, dW2, db2}, que serán las derivadas de dicho error con respecto a las distintas matrices y vectores de pesos de la red haciendo uso de la función \code{grad} de la biblioteca Theano. También señalar que la función de activación empleada para las neuronas de la red es la sigmoide.\\

También, y para agilizar el proceso de etiquetado de las imágenes de test y train para calcular las correspondientes tasas de error, hemos declarado diversas funciones theano que se ocupan de, a partir de una matriz de imágenes (ya que representamos las imágenes como vectores, pues no necesitamos, por ahora, tenerlas en forma matricial), calcular las etiquetas predichas por la red para ellas:

\begin{lstlisting}
A = T.matrix('A')
hidMatrix = 1.0 / (1.0 + T.exp(-(T.dot(A, W1) + b1)))
outMatrix = 1.0 / (1.0 + T.exp(-(T.dot(hidMatrix, W2) + b2)))
y_hatMatrix = T.nnet.softmax(outMatrix)
predictions = T.argmax(y_hatMatrix, axis = 1)
predictMatrix = function([A], predictions)
\end{lstlisting}

\subsection{Softmax}
\archive{backSoft.py}\\

Siguiendo los experimentos de los que se hablan en el guión de la práctica hemos implementado el algoritmo de backpropagation haciendo uso de una capa de salida de tipo softmax.\\

Para implementar esta capa de salida hemos hecho uso, como se ve en el código que hemos mostrado anteriormente, de la función \code{softmax} de Theano. También hemos de definir el error como el error de entropía cruzada, ya que si por ejemplo definimos el error como el error cuadrático medio, la tasa de error aumentará mucho. Además pese a que Theano dispone de una función para calcular este error, nos daba un error en cuanto al tipo del vector de salidas, con lo cual simplemente hemos definido nosotros mismos tal error, que como vemos resulta muy cómodo: el opuesto de la sumatoria del producto de cada salida de la red con la salida esperada; hacemos uso de la clase de cada imagen representada por medio de un vector binario. Los experimentos que hemos realizado sobre este algoritmo se han centrado en modificar el número de neuronas de la capa oculta así como la tasa de aprendizaje a fin de poder ver sus efectos.\\

Comenzamos el experimento con una capa oculta con 256 neuronas al igual que en el ejemplo planteado en el guión de la práctica. En un principio empleamos la tangente hiperbólica como función de activación, esto simplemente implica cambiar la declaración de las variables simbólicas que representan la salida de las dos capas de la red:

\begin{lstlisting}
#tanh like activation function
# hid = T.tanh(T.dot(x, W1) + b1)
# out = T.tanh(T.dot(hid, W2) + b2)

#sigmoid like activation function
hid = 1.0 / (1.0 + T.exp(-(T.dot(x, W1) + b1)))
out = 1.0 / (1.0 + T.exp(-(T.dot(hid, W2) + b2)))

#Lecun recommended tanh like activation function
# hid = 1.7159 * T.tanh(0.67 * (T.dot(x, W1) + b1) )
# out = 1.7159 * T.tanh(0.67 * (T.dot(hid, W2) + b2) )
\end{lstlisting}

El emplear esta función de activación hace que la tasa de error (9.68\%) sea algo mayor que la obtenida empleando la función logística, con lo cual, al igual que en el experimento del que estamos partiendo, emplearemos la función logística como función de activación para las neuronas de la red. Una vez fijada la función de activación y la de coste hemos pasado a experimentar con el número de neuronas en la capa oculta así como el número de pasadas que realizamos sobre el conjunto de entrenamiento. También se probó con la tangente hiperbólica con los coeficientes $a$ y $b$ propuestos por Yann Lecun pero también obteníamos un error mayor que el obtenido con la función logística con lo que optamos por ésta.\\

Los primeros experimentos se realizaron dando una única pasada al conjunto de entrenamiento. Al probar aumentar el número de neuronas en la capa oculta fue desconcertante el encontrar una tasa de error más alta que en el caso de tener únicamente 256 neuronas. Sin embargo cuando se realizó un experimento más extenso al dar hasta 100 pasadas al conjunto de entrenamiento, mostrando la tasa de error sobre el conjunto de test cada 5 pasadas los resultados fueron más lógicos.\\

Como podemos ver el hecho de aumentar el número de neuronas en la capa oculta hace que, a partir de un cierto número de pasadas, el error de la red con más neuronas ocultas se menor que el de la red más pequeña. Con lo que se pone de manifiesto que la red aprende mejor con más capas pero que necesita de más pasadas para tener una información que efectivamente sea útil. Cabe señalar que se realiza un proceso de aprendizaje online, actualizando los pesos cada vez que se le pasa una muestra a la red, he optado por esta opción ya que en las transparencias de teoría se informaba de que tal proceso solía dar mejores soluciones que el aprendizaje por mini-lotes.

\begin{figure}[H]
\includegraphics[scale=0.5]{img/cantidad.pdf}
\caption{Comparación de tasas de apredizaje}
\end{figure}

Lo que podemos apreciar también en los experimentos anteriores es, además del mayor tiempo requerido para el entrenamiento de una red con una capa oculta de mayor tamaño, es un ligero sobreaprendizaje, pero prácticamente inexistente, además en algunas pasadas posteriores la tasa de error en test vuelve a disminuir, con lo que realmente no podemos achacar este aumento del error a un sobreajuste. Sí es cierto que en los experimentos realizados a posteriori sobre la tasa de aprendizaje se aprecia que con un tasa de 0.01 el error siempre disminuye, pero de una forma mucho más lenta que con una tasa de 0.1. Debido a que, para la topologías estudiadas, no se ha apreciado un sobreajuste reseñable no se han incluido factores de regularización.\\

Por otro lado también se hizo una prueba para cambiar la tasa de aprendizaje a fin de comprobar si con una tasa más reducida el aprendizaje no aqueja el pequeño sobreajuste que experimentamos en los experimentos anteriores. En cambio lo que se observó es que, para el mismo número de pasadas, y con una capa oculta de 700 neuronas, el aprendizaje resultaba demasiado lento con una tasa menor, con lo que se empobrecían los resultados obtenidos. Por otro lado también observamos el efecto de diversas tasas de aprendizaje con una capa oculta de 256 neuronas dando 10 pasadas al conjunto de aprendizaje. Aquí también se vimos tanto un aprendizaje peor cuando la tasa es demasiado pequeña y un sobreajuste cuando la tasa es demasiado grande.

Esto puede apreciarse en las dos siguientes gráficas comparativas:

\begin{figure}[H]
\includegraphics[scale=0.5]{img/tasas.pdf}
\caption{Comparación de tasas de apredizaje}
\end{figure}

\begin{figure}[H]
\includegraphics[scale=0.5]{img/tasa.pdf}
\caption{Comparación de tasas de apredizaje}
\end{figure}

\begin{center}
\begin{table}[H]
\centering
\caption{Experimentos backpropagation}
\label{my-label}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\rowcolor[HTML]{FFFC9E} 
\textbf{\begin{tabular}[c]{@{}c@{}}Función\\ activación\end{tabular}} & \textbf{Error}   & \textbf{\begin{tabular}[c]{@{}c@{}}Nº neuronas\\ ocultas\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Tiempo\\ entrenamiento\\ (s)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Tasa\\ error\\ (\%)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Pasadas\\ al cojunto de \\ entrenamiento\end{tabular}} \\ \hline
tanh                                                                  & entropía cruzada & 256                                                                    & 14.52                                                                         & 9.68                                                                 & 1                                                                                         \\ \hline
logística                                                             & entropía cruzada & 256                                                                    & 12.53                                                                         & 7.57                                                                 & 1                                                                                         \\ \hline
logística                                                             & cuadrático medio & 256                                                                    & 12.75                                                                         & 90.68                                                                & 1                                                                                         \\ \hline
logística                                                             & entropía cruzada & 700                                                                    & 33.87                                                                         & 8.25                                                                 & 1                                                                                         \\ \hline
logística                                                             & entropía cruzada & 256                                                                    & 250.19                                                                        & 2.17                                                                 & 20                                                                                        \\ \hline
logística                                                             & entropía cruzada & 256                                                                    & 570.24                                                                        & 1.91                                                                 & 50                                                                                        \\ \hline
\end{tabular}
\end{table}
\end{center}

\subsection{Momentos}
\archive{backSoftMomentums.py}\\

A continuación pasamos a incorporar momentos en la actualización de pesos, nuevamente, esto resulta muy sencillo de implemetnar con Theano. Sólo tenemos que declarar nuevas variables donde almacenar el incremento de pesos anterior y modificar el parámetro \code{updates} de la función \code{train}:

\begin{lstlisting}
prevDeltaW1 = shared(np.zeros((784, nHidden), dtype = config.floatX), name = 'prevDeltaW1')
prevDeltab1 = shared(np.zeros(nHidden, dtype = config.floatX), name = 'prevDeltab1')
prevDeltaW2 = shared(np.zeros((nHidden, 10), dtype = config.floatX), name = 'prevDeltaW2')
prevDeltab2 = shared(np.zeros(10, dtype = config.floatX), name = 'prevDeltab2')

train = function([x, y], err,
    updates={
        (W2, W2 - lr * dW2 - eta * prevDeltaW2),
        (b1, b1 - lr * db1 - eta * prevDeltab1),
        (W1, W1 - lr * dW1 - eta * prevDeltaW1),
        (b2, b2 - lr * db2 - eta * prevDeltab2),
        (prevDeltab2, db2),
        (prevDeltaW1, dW1),
        (prevDeltaW2, dW2),
        (prevDeltab1, db1)})
\end{lstlisting}

Aquí se muestran los experimentos realizados con el mecanismo de momentos, se emplea una tasa de aprendizaje fija así como una tasa para los momentos también fija. En la leyenda de la gráfica \textit{lr} representa la tasa de aprendizaje y \textit{mr} la relativa a los momentos. Sí que se observó que el tiempo de entrenamiento requerido por la red era mayor, debido a la operación a realizar con el antiguo vector de incrementos:

\begin{figure}[H]
\includegraphics[scale=0.6]{img/momentos.pdf}
\caption{Comparación de tasas de apredizaje}
\end{figure}

\begin{table}[H]
\caption{Experimentos con momentos}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\rowcolor[HTML]{FFFC9E} 
\textbf{\begin{tabular}[c]{@{}c@{}}Nº neuronas\\ ocultas\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Pasadas\\ al conjunto\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Tasa\\ aprendizaje\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Tasa\\ momentos\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Tasa\\ error\\ (\%)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Tiempo\\ entranamineto\\ (s)\end{tabular}} \\ \hline
256                                                                    & 76                                                                     & 0.05                                                                & 0.05                                                             & 1.81                                                                 & 2003.057                                                                      \\ \hline
256                                                                    & 100                                                                    & 0.1                                                                 & 0.1                                                              & 1.72                                                                 & 2679.87                                                                       \\ \hline
700                                                                    & 66                                                                     & 0.1                                                                 & 0.1                                                              & 1.6                                                                  & 5308.86                                                                       \\ \hline
\end{tabular}
\end{table}

\section{Convolución}
\archive{convolutionalNN.py}\\

Por último decidimos programar una red de tipo convolucional para lo que seguimos un \href{http://deeplearning.net/tutorial/lenet.html}{tutorial} que nos ayuda a implementar una red de tipo Lenet5 con Theano de modo que sea eficiente para usar con GPU y además, podemos ver cómo programar de un modo más modularizado que el empleado en algoritmos anteriores. No obstante se ha variado algunos parámetros del algoritmo a fin de adaptarlo a nuestras necesidades. Así la topología que seguiría nuestra red sería la siguiente:

\begin{center}
\begin{tikzpicture}[shorten >=1pt,->,draw=black!10, node distance=\layersep]
    \tikzstyle{every pin edge}=[<-,shorten <=1pt]
    \tikzstyle{neuron}=[circle,fill=black!25,minimum size=10pt,inner sep=0pt]
    \tikzstyle{input neuron}=[neuron, fill=green!50, minimum size=5pt];
    \tikzstyle{convol neuron}=[neuron, fill=brown!50];
    \tikzstyle{output neuron}=[neuron, fill=orange!50, minimum size =10pt];
    \tikzstyle{hidden neuron}=[neuron, fill=gray!50];
    \tikzstyle{annot} = [text width=4em, text centered]

    % Draw the input layer nodes
    \foreach \name / \y in {0,1}
    % This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
        \node[input neuron, pin=left:$pixel_{\y}$] (I-\name) at (0,-0.5*\y cm) {};
    
    \node at (0,-0.5*3) {\vdots};
    \node[input neuron, pin=left:$pixel_{782}$] (I-782) at (0,-0.5*5) {};
    \node[input neuron, pin=left:$pixel_{783}$] (I-783) at (0,-0.5*6) {};
    
    % Draw first convol layer
    \foreach \name / \y in {1,...,6}
    		\node[convol neuron] (C-\name) at (\layersep,-0.5*\y cm) {};
    		
    	 % Draw second convol layer
    \node at (2*\layersep,-0.5*3) {\vdots};	
    	    	
    	\foreach \name / \y in {0,1,7,8}
        \path[yshift=0.5cm]
            node[convol neuron] (CC-\name) at (2*\layersep,-0.5*\y cm) {};

    % Draw the hidden layer nodes
    \node at (3*\layersep,-0.5*3) {\vdots};
    \foreach \name / \y in {0,1,7,8}
        \path[yshift=0.5cm]
            node[hidden neuron] (H-\name) at (3*\layersep,-0.5*\y cm) {};
    
    %Draw output layer nodes  
    \foreach \name / \y in {0,...,9}
        \path[yshift=0.5cm]
            node[output neuron, pin={[pin edge={->}]right:$salida_{\y}$}] (O-\name) at (4*\layersep,-\y*0.5 cm) {};

    % Connect every node in the input layer with every node in the
    % first convolutional layer.
    \foreach \source in {0,1,782,783}
        \foreach \dest in {1,...,6}
            \path (I-\source) edge (C-\dest);
            
    % Connect every node in the first convolutional layer with every node in the
    % second convolutional layer.
    \foreach \source in {1,...,6}
        \foreach \dest in {0,1,7,8}
            \path (C-\source) edge (CC-\dest);
            
    % Connect every node in the second convolutional layer with every node in the
    % hidden convolutional layer.
    \foreach \source in {0,1,7,8}
        \foreach \dest in {0,1,7,8}
            \path (CC-\source) edge (H-\dest);

    % Connect every node in the hidden layer with the output layer
    \foreach \source in {0,1,7,8}
    		\foreach \dest in {0,...,9}
        		\path (H-\source) edge (O-\dest);

    % Annotate the layers
    \node[annot,above of=H-0, node distance=1cm] (hl) {Capa oculta};
    \node[annot,left of=hl] (cp2) {Convol + Pool};
    \node[annot,left of=cp2] (cp1) {Convol + Pool};
    \node[annot,left of=cp1] {Entradas};
    \node[annot,right of=hl] {Salidas};
\end{tikzpicture}
\end{center}

Como vemos tenemos dos capas que realizan convolución y pooling; el pooling empleado reducirá la dimensionalidad de la matriz recibida a la mitad. En la primera capa de convolución tendremos sólamente 6 filtros de características o 6 neuronas convolucionales, y en la segunda tenemos 256. Después pasamos a una red neuronal usual con 256 neuronas en la capa oculta y las 10 neuronas de la capa de salida de tipo softmax que teníamos antes. En todas las neuronas estamos empleando la función sigmoidal como función de activación. El error que derivamos y propagamos en nuevamente el error de entropía cruzada. Pasamos a ver detalles de la implementación de este algoritmo:

Además de declarar dos clases para representar capas de tipo capa oculta que hemos empleado en otros algoritmos y capas de salida de tipo softmax, hemos definido también una clase que representa capas de tipo convolución:

\begin{lstlisting}
class convPoolLayer:
    def __init__(self, input, filter_shape, image_shape):
        self.input = input

        self.W = shared(np.random.normal(loc=0, scale=.1,
         size=filter_shape).astype(config.floatX), borrow = True)
        self.b = shared(np.random.normal(loc=0, scale=.1,
         size=filter_shape[0]).astype(config.floatX), borrow = True)

        conv_out = T.nnet.conv2d(input = input, filters = self.W,
         filter_shape = filter_shape, input_shape = image_shape)
        pooled_out = pool.pool_2d(input = conv_out, ds = (2,2), ignore_border  = True)

        self.output = 1.0 / (1.0 + T.exp(-(pooled_out +
         self.b.dimshuffle('x', 0, 'x', 'x'))))
        self.params = [self.W, self.b]
        self.input = input
\end{lstlisting}

Como vemos inicializamos los pesos en el intervalo [-0.1, 0.1], además el vector \code{filter\_shape} está compuesto por 4 valores: \code{(numero de canales o neuronas en la capa, numero de canales en la imagen de entrada (en nuestro caso 1), altura del filtro de convolucion, anchura del filtro de convolucion)}. Luego en el vector \code{image\_shape} tiene también 4 valores: \code{(tamano del minibatch (en nuestro caso 1 al emplear aprendizaje online), numero de canales en la imagen de entrada, alto imagen de entrada, ancho de la imagen de entrada)}.\\

A continuación empleamos la función \code{nnet.conv2d} para realizar la convolución de la imagen de entrada con el filtro de convolución empleado, esto hace que la salida tenga dimensión $dimensionEntrada - dimensionFiltro + 1$. A continuación realizamos un pooling sobre esta convolución empleando la función \code{pool.pool\_2d} que por el parámetro \code{ds} que le damos reduce a la mitad las dimensiones de la imagen.\\

Finalmente la salida es la evaluación de la función sigmoide sobre ese pooling añadiéndole el bias que hemos de redimensionar para que se pueda realizar dicha operación.\\

El resto del código es muy sencillo de entender ya que es muy parecido al que hemos venido utilizando en otros algoritmos, cambiando que ahora se definen las 4 capas de la red haciendo uso de los constructores de las clases definidas. Además desde la segunda capa de convolución hasta la capa oculta hemos de realizar una redimensionalización de la salida (\code{layer2\_input = layer1.output.flatten(2)}) para que las operaciones se realicen correctamente.

Experimentos con una red neuronal [6, 256, 256, 10] y en la siguiente gráfica se muestran los resultados obtenidos, con una tasa de aprendizaje de 0.1:

\begin{figure}[H]
\includegraphics[scale=0.6]{img/convolution.pdf}
\caption{Experimento con red convolucional}
\end{figure}

Como podemos ver el error obtenido queda por debajo del 1\%, el mejor resultado es de 0.85, que es el mejor resultado obtenido en este trabajo.\\

Traté de hacer otros experimentos ampliando el número de neuronas de convolución en la primera capa así como las neuronas en la capa oculta, pero dado que el entrenamiento es muy lento y que además los resultados obtenidos eran mucho peores (probablemente debido al sobreaprendizaje) decidí no realizar los experimentos. También probé a cambiar la función de activación a una ReLu pero, probablemente por no saber cómo usar este tipo de redes, los resultados era también muy malos.\\

\textcolor{red}{Señalar que este es el único algoritmo que hemos ejecutado con la GPU.}

\section{Resumen de resultados}

\begin{table}[H]
\centering
\caption{Resumen de resultados}
\label{my-label}
\begin{tabular}{|>{\columncolor[HTML]{FFFFC7}}c |c|c|c|c|c|}
\hline
\cellcolor[HTML]{FFFC9E}\textbf{Algoritmo} & \cellcolor[HTML]{9AFF99}\textbf{\begin{tabular}[c]{@{}c@{}}Archivo\\ algoritmo\end{tabular}} & \cellcolor[HTML]{9AFF99}\textbf{\begin{tabular}[c]{@{}c@{}}Archivo \\ pesos\end{tabular}} & \cellcolor[HTML]{FD6864}\textbf{\begin{tabular}[c]{@{}c@{}}\% Error\\ entrenamiento\end{tabular}} & \cellcolor[HTML]{FD6864}\textbf{\begin{tabular}[c]{@{}c@{}}\% Error\\ test\end{tabular}} & \cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}c@{}}Tiempo \\ entrenamiento\end{tabular}} \\ \hline
Plantillas 1                               & algTemplates1.py                                                                             & -                                                                                         & 44.17                                                                                                   & 44.17                                                                                          & 2.33                                                                                                  \\ \hline
Plantillas 2                               & algTemplates2.py                                                                             & -                                                                                         & 17.65                                                                                                   & 16.43                                                                                          & 2.36                                                                                                  \\ \hline
Plantillas 3                               & algTemplates3.py                                                                             & -                                                                                         & 16.13                                                                                                   & 15.52                                                                                           & 1.84                                                                                                  \\ \hline
Back +softmax                               & backSoft.py                                                                             & (*)                                                                                         & 0.53                                                                                                   & 1.82                                                                                          & 1161.96                                                                                                  \\ \hline
Momentos                               & backSoftMomentums.py                                                                                                                                                     & (**) & 0.47 & 1.6                                                                                          & 5308.86                                                                                                  \\ \hline
Convolución                               & convolutionalNN.py                                                                             & (***)                                                                                        & 0.21                                                                                                & 0.85                                                                                          & 5648.88                                                                                                  \\ \hline
\end{tabular}
\end{table}

(*) No sé qué archivo de pesos corresponde a este resultado. \\
(**) El archivo de pesos es backSoftwithMomentums0.1EPOCH65NHID700ETA0.1.npz\\
(***) basicconvolutional256.npz


\section{Manual de usuario}

\begin{itemize}
\item Dado que no se han podido entregar todos los ficheros necesarios debido al peso máximo permitido tendremos que:
	\begin{itemize}
	\item Descargar la base de datos facilitada.
	\item Crear el directorio data donde se almacenarán los archivos generado a partir de ella.
	\item Ejecutar el reader.py
	\item Crear los directorios weights y results donde se almacenarán, respectivamente, los pesos de las redes entrenadas y los resultados obtenidos.
	\end{itemize}
\item Los archivos generados a partir de la base de datos se encuentran en el directorio \archive{data} y han sido generados haciendo uso del código contenido en \archive{reader.py}. Si queremos volver a generar dichos ficheros tendremos que hacerlo ejecutando el reader con la instrucción que se muestra más adelante.
\item Los archivos con los pesos de las distintas redes entrenadas están el directorio \archive{weigths} y se han generado haciendo uso de la función \code{savez} de numpy, pueden cargarse dichos pesos usando la función \code{load} del mismo módulo Python.
\item Algunos archivos que almacenan resultados de las distintas redes están en el direcotrio \archive{results}.
\item Para ejecutar cualquiera de los algoritmos, una vez tengamos Theano correctamente configurado en nuestra máquina (tenemos tutoriales en la propia web) no hemos más de emplear la siguiente instrucción \code{THEANO\_FLAGS=mode=FAST\_RUN,\\device=cpu,floatX=float32 python ficheroAlgoritmo}. Cambiando si lo deseamos el valor del flag \code{device} por gpu.
\end{itemize}

\section{Bibliografía}

\begin{itemize}
	\item \href{http://deeplearning.net/software/theano/index.html}{Documentación Theano}
	\item \href{http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/}{Usando Theano para implementar backpropagation}
	
	\item \href{http://deeplearning.net/tutorial/lenet.html}{Tutorial redes convolucionales en Theano}
	\item \href{http://deeplearning.net/tutorial/mlp.html}{MLP con Theano, enlazado desde el anterior}
\end{itemize}


\end{document}